\chapterimage{unidades/1_computadoras/2_historia_computadoras/imagenes/cover}
\chapterimagedescription{Museo de Historia de las Computadoras en Mountain View,
California, EE.UU.}
\chapterimageauthor{Fotografía de Michael Kappel}

\chapter{Historia de las computadoras}
\index{Historia de las computadoras}
\label{chap:historia_computadoras}

La historia de las computadoras está directamente ligada a las historias de la
matemática, la lógica, la gramática y la ingeniería mecánica y electrónica. Así,
los seres humanos han utilizado dispositivos que los ayuden a computar
(calcular) diversas cosas desde hace milenios, así como desarrollado técnicas
que hoy en día se utilizan ampliamente en ciencias de la computación.

Este capitulo busca realizar un pequeño recorrido histórico por el desarrollo de
las ciencias de la computación, no solo desde una perspectiva del hardware, sino
también del software y de las teorías que sustentan a la disciplina. En el
transcurso de este viaje se espera que el lector no solo se lleve una serie de
anécdotas, sino que pueda apreciar el estado de las ciencias de la computación
en la actualidad como parte de un proceso evolutivo que continúa en desarrollo,
así como descubrir algunos conceptos que verá de forma recurrente si opta por
desarrollarse en la disciplina.

Pero no solo veremos el pasado de la computación, también haremos un pequeño
análisis del presente, para cerrar el capítulo con un vistazo a lo que depara el
futuro.

\section{Los precursores de las computadoras modernas}
\label{chap:historia_computadoras:sec:precursores}

Pensar que la computación es un desarrollo que se ha realizado solamente en los
últimos años del siglo XX es una idea ingenua. Los seres humanos hemos tenido la
necesidad de contar y calcular (\textbf{computar}) cosas desde hace mucho, mucho
tiempo; tanto tiempo como la prehistoria.

Desde el desarrollo de pequeños utensilios para asistir en los trabajos de
computo, pasando por el desarrollo de conceptos matemáticos y trabajos manuales
de trabajadores y trabajadoras cuyo esfuerzo nunca fue reconocido ni remunerado,
hasta el desarrollo de maquinarias con complejos engranajes que permitieran
asistir en el trabajo computacional. Todos terminan por ser precursores, de una
u otra forma, de un proceso mental que se fue generando en la humanidad; la
necesidad de contar con computadoras.

Y es que, a medida que avanza la ciencia y la técnica, también avanza la
necesidad de realizar cálculos cada vez más complejos, y cada vez, en menor
tiempo. Las computadoras no son una casualidad, son una necesidad intrínseca al
proceso de desarrollo científico-tecnológico que ha desarrollado la humanidad.

\subsection{La prehistoria de la computación}
\index{La prehistoria de la computación}
\label{chap:historia_computadoras:subsec:prehistoria}

\index{Hueso de Ishango}
Los registros cuentan que el ser humano parece haber comenzado a contar desde al
menos el año 20.000 AC. Por ejemplo, varios científicos, antropólogos e
historiadores nos comentan sobre la utilidad del \textbf{hueso de Ishango}, un
utensilio de hueso que data del paleolítico superior (20.000 AC.), y que habría
servido para realizar conteos y cuentas. Incluso pareciera que ya en esa época,
los seres humanos tenían alguna noción sobre números primos. Obviamente al no
haber registros escritos, es imposibles saberlo con
seguridad.\autocite{bogoshi_1987}

\index{Abaco@Ábaco}\index{Suanpan} Pero los verdaderos avances en materia de
cuentas comenzaron en la antigua Mesopotamia con la invención del \textbf{ábaco
sumerio}, al rededor del 2500 AC. El ábaco consiste en un cuadro de madera con
barras paralelas por las que corren una serie de bolas movibles. Este aparato
permitía realizar cálculos sencillos (sumas y restas). Los chinos pronto en el
190 AC. mejorarían la idea con la creación del \textbf{suanpan}, conocido
también como el \textbf{ábaco chino}. Este incluía las características del ábaco
sumerio, pero las ampliaba permitiendo realizar también multiplicaciones y
divisiones gracias a su innovador diseño.
\autocite[vid.]{boyer_1991}

\begin{knowwhat}
    El ábaco todavía se utiliza hoy en día para enseñarle operaciones sencillas
    a los niños, e incluso el suanpan es utilizado ampliamente por mercaderes,
    comerciantes y contadores en áreas donde el uso de tecnología es poco
    práctico.
\end{knowwhat}

\index{Carruaje que apunta al sur}
En el 910 AC se crea también en China el \textbf{carruaje que apunta al sur}, un
dispositivo que actúa de forma similar a una brújula, y que permitía a los
mercaderes orientarse en los caminos. Este dispositivo es el primero en utilizar
un engranaje, una de las piezas fundamentales de las \textbf{computadoras
mecánicas}.

\wraprimage{unidades/1_computadoras/2_historia_computadoras/imagenes/suanpan.jpg}
{Un suanpan. Su diseño permite contar en decimal y hexadecimal.} {Archivo de
David R. Tribble.}

\index{Mecanismo de Anticitera}
Pero si de engranajes hablamos, el \textbf{Mecanismo de Anticitera}, datado del
150 AC, es ya una completa \textbf{computadora mecánica}. Habría sido construido
por científicos griegos con la intención de calcular eventos astronómicos y
calendáricos, así como determinar la fecha exacta de los juegos olímpicos y
otros certámenes deportivos de la antigüedad. La complejidad de este aparato no
fue equiparada hasta siglos después, con la invención de los primeros relojes
mecánicos.\autocite{lin_2016}

\index{Binario}\index{Sistema Binario} En el área de las matemáticas, los
avances de los chinos, utilizando el número cero, y los números negativos, así
como los aportes del matemático Indio Pingala desarrollando el \textbf{sistema
de numeración binario}, el cual es la base de todas las computadoras modernas
sentarían las bases para la matemática moderna y por tanto para las ciencias de
la computación.

\index{Algoritmo}
El matemático Abu Abdallah Mu\d{h}ammad ibn M\={u}s\={a} al-Jw\={a}rizm\={i},
conocido en general como al-Juarismi, quien fue un prestigioso matemático,
astrónomo y geógrafo persa alrededor del año 800. Dentro de sus numerosas obras
se le atribuye el haber propuesto por primera vez la idea de que, mediante una
especificación clara y concisa de pasos a realizar, se podían calcular
sistemáticamente, y por tanto se podrían desarrollar dispositivos mecánicos
similares al ábaco que realizarán trabajaran sobre este para realizar las
cuentas en lugar de tener el usuario que emplear las manos. Este concepto es el
precursor de lo que hoy en día se conoce como \textbf{algoritmo} (llamado así
como una deformación del nombre al-Juarismi).

Por supuesto que solamente mencionamos algunos de los hitos más destacados del
mundo antiguo, el cual estuvo lleno de avances científicos y matemáticos que
aportaron de alguna forma u otra a las ciencias de la computación.

\subsection{Las computadoras humanas}
\index{Computadoras Humanas}

\image{unidades/1_computadoras/2_historia_computadoras/imagenes/human_computers.jpg}
{Imagen de una mujer operando una de las primeras computadoras, una IBM 704, en
el Jet Propulsion Laboratory de la NASA.} {Imagen de NASA/JPL-Caltech.}

A medida que la ciencia avanzaba, se volvía necesario muchas veces realizar gran
cantidad de cálculos para lograr comprender el universo que nos rodeaba. Por
ejemplo, las áreas de astronomía y de física, solían requerir una gran cantidad
de cuentas para arribar a conclusiones sobre las observaciones realizadas sobre
diversos fenómenos.

Así, era común que los científicos contrataban a personas que realizaban los
cálculos, mientras ellos se centraban en otros experimentos u observaciones. En
ocaciones en los que los cálculos tardarían semanas o meses para realizarse,
contrataban varias personas trabajando día y noche.

Las personas contratadas debían poseer sin embargo una serie de conocimiento
(saber leer y escribir, ser capaz de realizar cálculos matemáticos, etc.) que no
eran comunes en la población general. Esto y la necesidad de abaratar costos
llevó a que se contraten en general mujeres, generalmente de clases sociales
acomodadas y que hayan recibido educación. En un contexto donde la mujer no
trabajaba (salvo en el hogar) la remuneración ofrecida podía ser
baja.\cite[p23]{evans_2018}

A estas personas se las conocía como \textbf{computadoras}. El término que hoy
usamos para los dispositivos, deviene de esas mujeres que, en la mayoría de los
casos, la historía ha omitido de sus páginas.

Incluso luego de la invención de las primeras computadoras electromecánicas, las
computadoras humanas se seguían empleando, pues eran consideradas más fiables, e
incluso más económicas en algunos casos que comprar una computadora.

\begin{knowwhat}
    Alexis Clairaut, Jérôme Lalande, y Nicole-Reine Lepaute, los astrónomos que
    calcularon la fecha del retorno del cometa Halley en 1750, habían contratado
    a un equipo de computadoras humanas para realizar el cálculo. En ese equipo
    se encontraba Nicole-Reine Etable de la Brière Lepaute, una de las primeras
    mujeres de las cuales se tiene registro que oficiaron de computadoras.
\end{knowwhat}

\subsection{Las calculadoras mecánicas}
\index{Calculadoras Mecanicas@Calculadoras Mecánicas}
\label{chap:historia_computadoras:subsec:calculadoras_mecanicas}

\index{Pascal, Blaise}\index{Pascalina} En 1642 \textbf{Blaise Pascal},
matemático y físico francés, cansado de realizar cálculos manualmente,
desarrolló la primer calculadora mecánica de la cual se tengan registros, la
\textbf{Pascalina}.

\index{Leibniz, Gottfried}\index{Leibniz, Cilindro de}\index{Cilindro de
Leibniz} Era una pequeña caja de madera que tenía en la tapa una hilera de
discos numerados, con los agujeros para introducir los dedos y hacerlos girar.
Funcionaba con engranajes, de forma que cuando una rueda daba una vuelta
completa, avanzaba la otra rueda situada a su izquierda. Esta calculadora solo
podía realizar sumas y restas. En 1672, \textbf{Gottfried Leibniz}
perfeccionaría el dispositivo, creando el \textbf{Cilindro de Leibniz}, que
permitía además multiplicar y dividir.\autocite{chase_1980}

\begin{knowwhat}
    El Cilindro de Leibniz fue la base de numerosas calculadoras mecánicas
    creadas hasta la década de 1970, cuando finalmente se reemplazaron por
    calculadoras electrónicas.
\end{knowwhat}

\index{Babbage, Charles}\index{Maquina Diferencial@Máquina Diferencial} Pero el
invento tal vez más ambicioso fue el ideado por el matemático británico
\textbf{Charles Babbage}. Babbage creo la \textbf{Máquina Diferencial}, una
calculadora mecánica capaz de calcular gran cantidad de polinomios. Su máquina
funcionaba con engranajes metálicos conectados, como una gran pieza de
relojería. Babbage consiguió fondos de la Royal Astronomical Society para la
construcción de su máquina. Sin embargo nunca logró hacerla funcionar. Los
engranajes de la época no eran lo suficientemente buenos, y los materiales se
rompían o generaban vibraciones que desarmaban el equipo. Desesperado, Babbage
modificaba constantemente su diseño. Finalmente, la Royal Astronomical Society
cortaría el financiamiento y el proyecto sería abandonado.

\subsection{La primer computadora mecánica}
\index{Computadora Mecanica@Computadora Mecánica}
\label{chap:historia_computadoras:subsec:maquina_analitica}

\index{Babbage, Charles}\index{Maquina AnalíticaMáquina Analítica} Años después,
en 1833, Charles Babbage volvería a intentarlo, pero esta vez, con una idea
todavía más radical, la \textbf{Máquina Analítica}. Este equipo tenía la
característica de ser \textbf{programable}. Es decir, se podía configurar para
realizar distintas tareas en distintos momentos. Los planos diseñados por
Babbage definían un complejo equipo capaz de realizar diversos cálculos,
almacenar los resultados en una memoria, y hasta imprimirlos con un dispositivo
similar a una impresora.\

\begin{knowwhat}[Sobre hombros de gigantes]
Babbage no inventó todo de cero. Su sistema de engranajes se basaba en gran
parte en el Cilindro de Liebniz. Como característica adicional su máquina
permitía ser programada mediante tarjetas perforadas.

\index{Jaquard, Joseph Marie}\index{Tarjeta Perforada} El sistema fue copiado de
un telar creado en 1801 por \textbf{Joseph Marie Jaquard}, un tejedor y
comerciante francés. El telar de Jaquard era \textbf{programable} a través de un
sistema de \textbf{tarjetas perforadas}, y permitía a una persona diseñar
complejos patrones en el tejido. Esta idea revolucionaria permitía reducir
costos al permitir diseñar tejidos complejos con un muy bajo esfuerzo y reducido
personal.

El invento de Babbage hubiera estado dotado de la mejor tecnología de la época.
\end{knowwhat}

\wraplimage[0.25]{unidades/1_computadoras/2_historia_computadoras/imagenes/charles_babbage.jpg}
{Charles Babbage (1860).} {Dominio Público.}

\index{Lovelace, Ada}
Charles Babbage buscó desesperadamente financiamiento para su dispositivo, pero
tras el fracaso anterior, el gobierno y los inversores privados eran escépticos.
Sin embargo, una joven aristócrata y matemática se acercó a Babbage por sus
diseños. Se trataba de Augusta Ada Byron, Condesa de Lovelace, conocida más
simplemente como \textbf{Ada Lovelace}, hija del famoso poeta Lord Byron. Ada
reconoció el potencial en los diseños de Babbage, y comenzó a diseñar programas
para el dispositivo. Por este motivo \textbf{Ada Lovelace se considera la primer
programadora de la historia}.\autocite{fuegi_2003}

Los deficientes materiales y técnicas de construcción de la época hicieron que
todos los esfuerzos de Babbage por construir la máquina analítica sean un
fracaso. Así, el proyecto cayó en el olvido. Sin embargo, muchos años después,
su máquina sería recreada utilizando los planos originales, y se demostraría que
esta funcionaba correctamente. Por esto, \textbf{Charles Babbage es considerado
el padre de la computadora moderna, así como de la impresora}. Además, realizó
numerosas contribuciones a las áreas de la matemática y de la criptografía.

\section{El despertar de la computación}
\label{chap:historia_computadoras:sec:despertar}

La computación se empieza a plantar como una realidad cada vez más inminente con
llegada del nuevo siglo (1900). Las ideas de Babbage serían reflotadas, ya en
una época en donde los avances en la técnica metalúrgica permitía crear mejores
dispositivos mecánicos y en donde los descubrimientos en materia de electricidad
planteaba nuevas posibilidades.

Muchos científicos y matemáticos comienzan a plantearse las posibilidades y los
límites de dispositivos que computen, o realicen pruebas matemáticas
automatizadas, y grandes avances se realizan en estos términos, dando lugar a
las ciencias de la computación como una disciplina nueva dentro de la rama de
las matemáticas, pero que interactúa en gran medida con la electrónica, la
mecánica y la ingeniería.

La Primera Guerra Mundial, y el advenimiento de una segunda gran guerra, en
donde contar con una superioridad tecnológica podía ser clave para la victoria,
llevó a que gobiernos tanto del eje como aliados financiaran serios desarrollos
e investigaciones en el área.

\subsection{La computación como teoría}
\index{Teoria de la Computacion@Teoría de la Computación}
\label{chap:historia_computadoras:subsec:teoria_computacion}

\index{Hillbert, David}
En 1920 la matemática atravesaba una fuerte crisis. Los nuevos conceptos y
abstracciones desarrollados en la disciplina a finales del siglo XIX traían
aparejadas una serie de paradojas e inconsistencias en los fundamentos básicos
de la matemática. En ese contexto, \textbf{David Hillbert}, un matemático
alemán, propuso un proyecto de investigación conocido como ``programa de
Hillbert'', que intentaba solucionar el problema mediante la reformulación de la
matemática sobre bases solidas y completamente lógicas. Hillbert creía que, en
principio, esto podía lograrse, mostrando dos cosas:
\begin{enumerate}
    \item Toda la matemática se sigue de un sistema finito de axiomas escogidos
    correctamente.
    \item Se puede probar que tal sistema axiomático es consistente.
\end{enumerate}

\index{Godel, Kurt@Gödel, Kurt}\index{Teorema de la Incompletitud} En 1931,
\textbf{Kurt Gödel} publicaría su \textbf{teorema de la incompletitud},
demostrando que no se podía probar la completitud de ningún sistema formal no
contradictorio que fuera suficientemente amplio para incluir al menos la
aritmética, sólo mediante sus propios axiomas. Así probó que el ambicioso plan
de Hilbert era imposible tal como se planteaba.\autocite[cap. 3]{petzold_2008}

\index{Teoria de la Computabilidad@Teoría de la Computabilidad}
La necesidad de comprender las implicancias del trabajo de Gödel llevaron pronto
al desarrollo de la \textbf{teoría de la computabilidad} y de allí a la
\textbf{lógica matemática} como disciplina autónoma en los años 30. Esto sería
la base para los desarrollos teóricos en ciencias de la computación realizados
por Alonzo Church y Alan Turing.

La \textbf{teoría de la computabilidad} comenzó a estudiar que problemas pueden
ser resueltos mediante un \textbf{algoritmo} lo cual permite de alguna forma
saber que problemas pueden ser resueltos mediante una computadora, y cuales no.

\begin{definition}\index{Algoritmo} Un \textbf{algoritmo} es un conjunto
    prescrito de instrucciones o reglas bien definidas, ordenadas y finitas que
    permiten llevar a cabo una actividad mediante pasos sucesivos que no generen
    dudas a quien deba hacer dicha actividad.
\end{definition}

\wraprimage{unidades/1_computadoras/2_historia_computadoras/imagenes/turing_church.jpg}
{Alan Turing (izq.) y Alonzo Church (der.).} {Fotografía de Dominio Público.
Universidad de Princeton.}

\index{Turing, Alan}\index{Turing, Maquina de@Turing, Máquina de}\index{Maquina
de Turing@Máquina de Turing} En Inglaterra, en 1936, \textbf{Alan Turing}
desarrolla un modelo matemático conocido como \textbf{Máquina de Turing}. Si
bien se conoce como ``máquina'', no hay ninguna construcción física involucrada,
sino que se trata de un dispositivo hipotético, capaz de llevar adelante un
algoritmo con el fin de solucionar un problema.

El dispositivo imaginado por un Turing consiste en un cabezal que manipula
símbolos sobre una tira de cinta que se extiende infinitamente, basándose en una
tabla de reglas. A pesar de su simplicidad, una máquina de Turing puede ser
adaptada para simular la lógica de cualquier algoritmo de computadora y es
particularmente útil en la explicación de las funciones del CPU dentro de una
computadora.

El modelo formal de computadora de Turing le permitió demostrar que
\textbf{existían problemas que una computadora no podía resolver, sin importar
que tan poderosa fuera la misma}. Demostró que es imposible resolver el
``Entscheidungsproblem'', un problema matemático planteado por Liebniz en el
siglo XVII, y retomado por Hillbert al plantear su propuesta de refundar la
matemática.\autocite[cap. 12]{petzold_2008}

\index{Church, Alonzo}
Al mismo tiempo pero del otro lado del Océano Atlántico, en Estados Unidos,
\textbf{Alonzo Church} desarrolla un modelo matemático conocido como
\textbf{cálculo lambda}, un sistema formal diseñado para investigar la
definición de función, la noción de aplicación de funciones y la recursión.

Se puede considerar al cálculo lambda como el lenguaje universal de
programación. Consiste en una regla de transformación simple (sustitución de
variables) y un esquema simple para definir funciones. Hoy en día este modelo
teórico es la base para el análisis formal de problemas computacionales, así
como la creación de nuevos lenguajes de programación.

El cálculo lambda permitía probar, de forma similar a las máquinas de Turing,
que \textbf{hay problemas que no pueden solucionarse con un una computadora}.
Así, de forma independiente y mediante métodos distintos, dos científicos habían
llegado a la misma conclusión.

\index{Church Turing, Tesis de@Church-Turing, Tésis de}\index{Tesis de Church
Turing@Tésis de Church-Turing} Posteriormente se formularía la \textbf{tesis de
Church-Turing}, la cual formula hipotéticamente la equivalencia entre los
conceptos de función computable y máquina de Turing, que expresado en lenguaje
corriente vendría a ser ``todo algoritmo es equivalente a una máquina de
Turing''. Esto quiere decir que el cálculo lambda y las máquinas de Turing, así
como otros formalismos creados para analizar las posibilidades de la
computación, son todas equivalentes.
\autocite[cap. 11]{petzold_2008}

Lo interesante de estos desarrollos es que por primera vez se demostraron, no
las utilidades prácticas de contar con computadoras, sino los límites de las
mismas, pero también sus enormes posibilidades. Los formalismos desarrollados
por estos científicos siguen presentes actualmente y son la base sobre la que se
sustentan muchos de los avances en ciencias de la computación.

\subsection{Primeras computadoras electromecánicas}
\index{Computadora Electromecanica@Computadora Electromecánica}
\label{chap:historia_computadoras:subsec:computadoras_electromecanicas}

Ya llegada la mitad de la década de 1930 nos encontramos en un contexto en donde
los trabajos de Babbage comienzan a hacer soñar a muchos científicos e
ingenieros. Además, los nuevos trabajos teóricos de Turing y Church auguraban
grandes posibilidades para la computación.

\index{Z1}\index{Z2}\index{Rele@Relé} Considerado hoy el inventor de las
computadoras modernas, Konrad Zuse diseño la \textbf{Z1} en 1935, y terminó de
construirla en 1938. La Z1 era una máquina completamente mecánica, era sumamente
lenta y solo funcionaba unos pocos minutos cada vez sin necesidad de reajustes.
Sin embargo, era la primer computadora realmente funcional. Más tarde realizó
una segunda versión de su computadora utilizando \textbf{relés} (una especie de
interruptor operado mediante magnetismo), bautizada la \textbf{Z2}.

\image{unidades/1_computadoras/2_historia_computadoras/imagenes/zuse_z3.jpg}
{Réplica de la Z3 de Zuse, la primer máquina completamente automática y digital
(electromecánica) en el Deutsches Museum en Alemania.} {Archivo del Deutsches
Museum.}

\index{Z3}
Esperando conseguir financiamiento para sus proyectos, presentó la Z2 al
Deutsche Versuchsanstalt f\"{u}r Luftfahrt (Laboratorio Alemán para la Aviación)
en 1940, siendo la presentación una de las pocas veces en que la Z2 funcionará
realmente. De está forma consiguió el financiamiento del gobierno para crear la
\textbf{primer computadora digital, automática y programable del mundo, la Z3}.
Completada en 1941, la Z3 fue construida utilizando 2.600 relés y operaba a una
velocidad de 4 o 5 Hz. Se debía inicializar la computadora manualmente, y
ejecutaba programas que se almacenaban en cintas perforadas. La Z3 no fue
considerada de vital importancia por el gobierno alemán durante la Segunda
Guerra Mundial, por lo que operó poco tiempo antes de terminar destruida tras
los bombardeos aliados a Berlin. Por haberse desarrollado en Alemania bajo el
gobierno de Hitler, la historia omitió durante años el trabajo de Zuse.
\autocite[cap. I]{ceruzzi_2003}

En el bando de los aliados, en Estados Unidos, comienzan a aparecer proyectos de
desarrollos de computadoras, apoyadas por el estado (generalmente por la rama
militar), universidades o empresas privadas.

\index{Tubo de Vacio@Tubo de Vacío}
Los avances en la tecnología y la reducción de costos permitían reemplazar relés
(que contenían piezas mecánicas) con \textbf{tubos de vacío}, un dispositivo que
actuaba de la misma forma, pero completamente electrónico, sin piezas móviles.
Como contrapartida los tubos de vacío se iluminaban y generaban gran cantidad de
calor, y en sus primeras versiones requerían de gran cantidad de espacio.

\index{ENIAC}
Ya en 1944 aparece \textbf{ENIAC}, financiada por el Ejercito de los Estados
Unidos, y utilizada para el cálculo de trayectorias balísticas. La computadora
ocupaba un sótano entero en la Universidad de Pensilvania. Físicamente, la ENIAC
tenía 17468 tubos de vacío, 7200 diodos de cristal, 1500 relés, 70000
resistencias, 10000 condensadores y cinco millones de soldaduras. Pesaba 27
Toneladas, medía $2,4m$x$0,9m$x$30m$ ($167m^2$), requería la operación manual de
unos 6000 interruptores, y su programa o software, cuando requería
modificaciones, demoraba semanas de instalación manual.
\autocite[p. 59]{ceruzzi_2012}

\index{Harvard Mark I}\index{ASCC} No poco después aparece la primer computadora
construida por \textbf{IBM}, una de las empresas que más aportaría a la
computación mundial. La computadora en cuestión, el \textbf{IBM Automatic
Sequence Controlled Calculator (ASCC)}, más conocido como \textbf{Harvard Mark
I}, fue una computadora electromecánica, construida por IBM y enviado a Harvard
en 1944. Tenía 760.000 ruedas y 800 kilómetros de cable y se basaba en la
máquina analítica de Charles Babbage. Medía unos 15,5 metros de largo, unos 2,40
metros de alto y unos 60 centímetros de ancho, pesaba aproximadamente unas cinco
toneladas y poseía unas cubiertas de cristal que dejaban que se admirara toda la
maquinaria de su interior.
\autocite[p. 32]{ceruzzi_2012}

\begin{knowwhat}
    ENIAC fue creada por \textbf{John Presper Eckert} y \textbf{John William
    Mauchly}, quienes se llevaron el crédito principal, pero su programación fue
    realizada exclusivamente por 6 mujeres que fueron generalmente omitidas de
    los libros de historia: \textbf{Betty Snyder Holberton}, \textbf{Jean
    Jennings Bartik}, \textbf{Kathleen McNulty Mauchly Antonelli},
    \textbf{Marlyn Wescoff Meltzer}, \textbf{Ruth Lichterman Teitelbaum} y
    \textbf{Frances Bilas Spence}.
\end{knowwhat}

\image{unidades/1_computadoras/2_historia_computadoras/imagenes/eniac.jpg}
{Glen Beck y Betty Snyder programan la ENIAC en el edificio 328 de la Ballistic
Research Laboratory (Filadelfia, Pensilvania).} {Fotografía del Ejercito de los
Estados Unidos.}

\index{EDVAC}
Al ENIAC le sucedió \textbf{EDVAC}, utilizado también para balística, mientras
que los ingleses desarrollaron las máquinas \textbf{Colossus} (creadas con
intención de descifrar los códigos alemanes). Otras como \textbf{UNIVAC} (la
primera en ser vendida en los Estados Unidos) y la \textbf{Z4} de Zuse les
sucedieron. Las computadoras eran todavía artefactos muy costosos (EDVAC por
ejemplo tuvo un costo aproximado de unos US\$ 100.000) y utilizados en principio
solo con fines militares, pero pronto expandiéndose hacia la investigación
científica y los negocios.

\begin{knowwhat}\index{Debugging}\index{Debuggear} Los tubos de vacío atraían
    insectos que se quedaban en ellos, causando el mal funcionamiento de los
    equipos. Lo técnicos debían entrar y remover los insectos para que la
    computadora vuelva a funcionar. A este proceso se le conoce como
    \textbf{debuggear} (del inglés quitar los bichos). El término quedó, y hoy
    en día se conoce con ese nombre al proceso de arreglar los errores en un
    programa.
\end{knowwhat}

A medida que aparecían más y más computadoras, también se comenzó a desarrollar
una idea más seria sobre \textbf{arquitectura de computadoras}. Es decir, se
comenzaron a desarrollar modelos y descripciones funcionales de los
requerimientos y las implementaciones de diseño para varias partes de un
computadora, en especial en la forma en que el procesador trabaja internamente y
accede a las direcciones de memoria.

\begin{definition}\index{Arquitectura de Computadora} La \textbf{arquitectura de
    computadoras} es el diseño conceptual y la estructura operacional
    fundamental de un sistema de computadoras.
\end{definition}

\index{Von Neumann, John}\index{Von Neumann, Arquitectura de}
\index{Arquitectura de Von Neumann}\index{Arquitectura de
Harvard}\index{Harvard, Arquitectura de} La Mark I sentó las bases para lo que
hoy se conoce como \textbf{arquitectura de Harvard}, que involucra una
computadora en donde las pistas de almacenamiento y de señal se encuentran
físicamente separadas para las instrucciones y para los datos. Por otro lado
\textbf{John Von Neumann}, un matemático húngaro-estadounidense desarrolló el
primer borrador sobre la arquitectura de EDVAC, describiendo detalles
arquitecturales que simplificaban la arquitectura de Harvard, además de
optimizar costos. La arquitectura pasó a ser conocida como \textbf{Arquitectura
de Von Neumann}, y se transformó en un estándar, al punto de que casi todas las
computadoras modernas la utilizan.\autocite[sec 1.11]{patterson_2002}

\subsection{IBM, Bell y grandes computadoras}
\index{IBM}\index{Bell Labs}\index{Grandes Computadoras}
\label{chap:historia_computadoras:subsec:grandes_computadoras}

Ya terminada la guerra, el boom de las computadoras estaba en el aire, y el
potencial de estos dispositivos en otras áreas distintas a la guerra comenzaban
a vislumbrarse.

Una empresa venía ya vendiendo dispositivos electrónicos para grandes compañías
y fábricas, como máquinas tabuladoras y relojes de fichada. Se trataba de
\textbf{IBM}. Con la experiencia del desarrollo del \textbf{Harvard Mark I}, y
tras terminada la guerra, IBM crea la \textbf{IBM 701} (1953), considerada la
primer computadora comercial basada en tubos de vacío. Se siguieron pronto otros
modelos, como la \textbf{IBM 702} y la \textbf{IBM 650}.

\begin{knowwhat}
    En 1956, \textbf{Arthur L. Samuel}, del laboratorio de IBM en Poughkeepsie,
    Nueva York, programó un IBM 704 para jugar a las damas utilizando un método
    por el que la máquina podía ``aprender'' a partir de su propia experiencia.
    Se cree que este es el primer programa de ``auto-aprendizaje'', una
    demostración del concepto de \textbf{inteligencia artificial}.
\end{knowwhat}

IBM se transformó rápidamente en la empresa líder en todo lo referente a
computadoras. Invirtiendo gran cantidad de dinero en investigación y desarrollo
(I+D). En 1957 IBM desarrolló el primer sistema de almacenamiento informático
basado en disco, llamado el IBM 305 RAMAC. El \textbf{RAMAC ATOGA} es el
predecesor de los discos duros actuales y estaba formado internamente por
cincuenta discos.\autocite{pugh_1996}

\begin{knowwhat}
    IBM también desarrolló el lenguaje de programación científico
    \textbf{FORTRAN} (FORmula TRANslation) para facilitar la creación de
    programas. También fueron los inventores de otras tantas tecnologías
    ampliamente utilizadas hoy en día, como, \textbf{la memoria RAM},
    \textbf{las tarjetas magnéticas} y \textbf{los códigos de barras}.
\end{knowwhat}

\index{AT\&T}
IBM no fue la única empresa que incursionó en tecnología. Otra de las grandes
empresas que lo haría sería \textbf{AT\&T} quien controlaba los teléfonos de
Estados Unidos de forma monopólica, y principalmente su subsidiaria,
\textbf{Bell Labs} (que gracias al monopolio contaba con uno de los presupuestos
más altos del mundo en términos de investigación en tecnología).

Entre las patentes y descubrimientos más importantes de Bell Labs destacan
\textbf{la libreta de un solo uso}, \textbf{el transistor}, \textbf{el láser},
\textbf{la fibra óptica}, \textbf{la tecnología DSL}, \textbf{la telefonía
móvil}, \textbf{los satélites de comunicaciones}, \textbf{el sistema operativo
Unix}, \textbf{el lenguaje de programación C} y \textbf{el lenguaje de
programación C++}. Además, once de sus investigadores han sido galardonados con
Premios Nobel.\autocite{gertner_2013}

\image{unidades/1_computadoras/2_historia_computadoras/imagenes/pdp_11.jpg}
{Ken Thompson (sentado) y Dennis Ritchie (parado), creadores de UNIX, trabajando
en Bell Labs en una PDP-11.} {Fotografía de Peter Hamer.}

Las computadoras sin embargo, seguían siendo costosas, grandes, pesadas, y
requerían de personal altamente capacitado para su instalación y armado. Por eso
solamente se encontraban disponibles en universidades, dependencias del estado o
grandes empresas privadas, que podían solventar los costos de estos aparatos.

Cabe destacar que la operación de las computadoras era tarea compleja.
\textbf{Programarlas requería de expertos, que supieran como estaba armada la
computadora (como estaban diagramados los cables, los circuitos, etc)} y por
tanto, solamente ingenieros electrónicos o matemáticos eran capaces de
operarlas. Adicionalmente, \textbf{como cada computadora era distinta, un
programa escrito para una computadora no funcionaba en otra}, y un profesional
que supiera operar una computadora tenía que volver a aprender todo de cero para
poder operar otra. Comprar una computadora era realizar un compromiso a largo
plazo con el fabricante, y por eso las pequeñas empresas no podían competir
contra compañías como IBM, que podían ofrecer profesionales capacitados,
mantenimiento y muchos otros servicios al comprador de sus equipos.

\subsection{Los lenguajes de programación}
\index{Lenguajes de Programacion@Lenguajes de Programación}
\label{chap:historia_computadoras:subsec:lenguajes}

\wraprimage{unidades/1_computadoras/2_historia_computadoras/imagenes/punch_cards.jpg}
{Un programa escrito en tarjetas perforadas. Las marcas en la parte superior de
la pila de cartas permitía identificar el programa y visualizar sus diversas
partes.} {Fotografía de Arnold Reinhold.}

Las primeras computadoras no venían con software para el usuario final, sino que
solamente permitían ser programadas. Es decir, todo usuario de la computadora
debía primero transformarse en un programador. El proceso de programar implicaba
conocer la arquitectura del equipo, y pasar las ideas que tuviera el usuario a
complejos códigos en tarjetas perforadas (es decir, había que aprender en que
lugares perforar para lograr el comportamiento deseado del equipo, algo que
además variaba de máquina a máquina).

Los primigenios programadores, debían lidiar constantemente con la
incompatibilidad de los programas que escribían. Así, un científico en Harvard
no podía simplemente darle su programa a alguien en Princeton, pues las
computadoras eran distintas, y por tanto, también los programas que se escribían
para ellas. Tampoco era sencillo actualizar una computadora simplemente
comprando una nueva, pues los programas ya escritos dejaban de funcionar.

Con la intención de solventar estos problemas, y reducir adicionalmente los
costos asociados a la programación de las computadoras, es que aparecieron los
primeros \textbf{lenguajes de programación}. Estos permitían programar la
computadora mediante un conjunto de instrucciones fáciles de recordar por los
programadores.\autocite[cap. 3]{ceruzzi_2003}

A medida que avanzaba la técnica, también avanzaban los lenguajes de
programación. Comenzaron a crearse lenguajes que funcionaban en múltiples
computadoras. Así, el usuario podía escribir un programa en FORTRAN o COBOL, que
funcionara en todos los equipos que soportaran dicho lenguaje de programación.
Esto era un gran avance, no solo en términos de expansión del conocimiento, sino
también en la reducción de tiempos, y por tanto costos, en los procesos de
desarrollo. Adicionalmente, el desarrollo de software dejaba gradualmente de ser
un trabajo solo de científicos y matemáticos, para pasar a ser algo que podía
realizar cualquier persona con algo de formación.

Los lenguajes más avanzados permiten a los programadores expresar mejor sus
ideas, y cuanto menor el trecho entre la idea y la aplicación en el equipo,
menor el tiempo que toma llevar la idea adelante.

\subsection{La revolución de los transistores y los circuitos integrados}
\index{Transistores}\index{Circuitos Integrados}
\label{chap:historia_computadoras:subsec:transistores}

La verdadera revolución en el campo de las computadoras surge con la invención
del \textbf{transistor}. Este dispositivo reemplazaba al tubo de vacío, siendo
mucho más fiable, económico, duradero, pero por sobre todo, pequeño que el tubo.

Los transistores permitían disminuir significativamente el tamaño, el peso y la
complejidad de una computadora. Además, a medida que avanzaba la técnica, los
mismos se podían hacer más y más pequeños.

\begin{knowwhat}
El transistor moderno que utilizamos en nuestras computadoras ronda los 14nm
(nanómetros). Además, se han creado exitosamente transistores más pequeños, de
tan solo 5 y 6 nm, e incluso de 1nm (aunque son todavía experimentales).

Para tener una comparación, el virus del VIH mide 100nm, un glóbulo rojo
aproximadamente 1000nm, y un grano de arena mide entre 63000nm y 200000nm.
\end{knowwhat}

\wraplimage{unidades/1_computadoras/2_historia_computadoras/imagenes/intel_4004.jpg}
{Un procesador Intel 4004.} {Fotografía de Thomas Nguyen.}

\index{Kilby, Jack S.}\index{Texas Instruments}\index{Chip}\index{Microchip} En
1959 el ingeniero \textbf{Jack S. Kilby} mientras trabajaba para la empresa de
tecnología \textbf{Texas Instruments} desarrolló el primer \textbf{circuito
integrado} (también conocido como \textbf{chip} o \textbf{microchip}). Consistía
en la integración de seis transistores en un mismo dispositivo. En el año 2000
Kilby fue galardonado con el Premio Nobel de Física por la enorme contribución
de su invento al desarrollo de la tecnología.\autocite{reid_2001}

La capacidad de producción masiva de circuitos integrados, su confiabilidad y la
facilidad de agregarles complejidad, llevó a su estandarización, reemplazando
circuitos completos con diseños que utilizaban transistores discretos, y además,
llevando rápidamente a la obsolescencia a las válvulas o tubos de vacío.

\begin{definition}
    \index{Chip}\index{Microchip}\index{Circuito Integrado} Un \textbf{chip} o
    circuito integrado (CI) o microchip, es una estructura de pequeñas
    dimensiones de material semiconductor, normalmente silicio, sobre la que se
    fabrican circuitos electrónicos mediante fotolitografía y que está protegida
    dentro de un encapsulado de plástico o de cerámica.
\end{definition}

Gracias a este avance, las computadoras ya no requerían enormes cuartos para su
instalación, ni pesaban toneladas. Asimismo, el bajo costo de los chips volvía a
la computadora un dispositivo asequible por ``cualquier'' persona (seguían
siendo equipos caros, pero el costo ahora era equiparable al de un vehículo
automotor).

\section{La modernidad de las computadoras}
\label{chap:historia_computadoras:sec:modernidad}

En la década de 1970 surge un quiebre en la historia de las computadoras. La
invención del chip, como elemento de bajo costo, hace que entusiastas y empresas
sean capaces de armar sus propios equipos.

Con la reducción de costos, la estandarización del código gracias a lenguajes de
programación, y una economía en auge, decenas de empresas comenzaron a producir
computadoras (o en su defecto componentes y software para computadoras). Muchas
de esas empresas hoy son líderes en la industria informática.

Por otro lado, el desarrollo de ideas democratizadoras de tintes socialistas
llevó al desarrollo de software por parte de comunidades auto-convocadas, sin
fines lucrativos, sino sociales.

Todos estos elementos son los que llevan al estado actual de las computadoras y
de la informática, transformando a estos dispositivos en una parte fundamental
de las sociedades modernas.

\subsection{Las primeras microcomputadoras}
\index{Microcomputadoras}
\label{chap:historia_computadoras:subsec:microcomputadoras}

A mediados de la década de 1970, comenzaron a aparecer las primeras
\textbf{microcomputadoras}, equipos de tamaño sumamente reducido en comparación
a las grandes computadoras que dominaban la escena de la época (aunque grandes
para los estándares actuales).

\index{SMP80/88}\index{Micral N}\index{Altair 8800} La primer microcomputadora
fue la japonesa \textbf{SMP80/08} de Sord Computer Corporation (1972), a lo que
siguió la francesa \textbf{Micral N}. En 1974 aparece en los Estados Unidos el
\textbf{Altair 8800}, que era vendido como un conjunto que debía ser ensamblado
por el usuario.

\begin{knowwhat}
La Altair 8800 solamente contaba con unos pocos interruptores e indicadores
lumínicos, y no tenía ni pantalla, ni teclado, ni nada parecido.
\end{knowwhat}

\index{Intel 8080}\index{Z80}\index{Motorola 6800} La revolución de los
circuitos integrados y sus reducidos costos hizo que comenzaran a aparecer
clubes de entusiastas y amantes de la electrónica y la tecnología, que se
juntaban para compartir piezas, intercambiar planos, conocimiento, diseños y
software. Aparece en esta época el \textbf{microprocesador}. Sumamente
económicos, consistían en un complejo circuito integrado que cumplía múltiples
funciones, antes realizadas por varios chips. Los \textbf{Intel 8080}, los
\textbf{Z80} y los \textbf{Motorola 6800} serían los procesadores que
potenciarían toda un generación de computadoras y consolas de videojuegos,
transformándose en emblemas de la era.\autocite[cap. 4-6]{ceruzzi_2003}

\begin{definition}
    \index{Microprocesador}
    Un \textbf{microprocesador} es el circuito integrado central más complejo de
    un sistema informático. Es el encargado de ejecutar los programas, desde el
    sistema operativo hasta las aplicaciones de usuario. Puede contener una o
    más unidades centrales de procesamiento (CPU).
\end{definition}

\index{Homebrew Computer Club}\index{Wozniak, Steve}\index{Jobs,
Steve}\index{Apple} El \textbf{Homebrew Computer Club}, uno de estos clubes de
entusiastas más influyentes y conocidos surgió en 1975 en \textbf{Silicon
Valley, California}. Fue considerado como ``el crisol de una industria entera'',
pues de allí surgieron influyentes personajes, e incluso empresas. En
particular, \textbf{Apple} surge de los trabajos realizados en ese club por
parte de \textbf{Steve Jobs} y \textbf{Steve Wozniak}.

\image{unidades/1_computadoras/2_historia_computadoras/imagenes/homebrew.jpg}
{Steve Jobs (parado) y Steve Wozniak (sentado) miembros del Homebrew Computers
Club diseñando su primer computadora, la Apple I.} {Fotografía de Apple
Computer.}

\index{Gates, Bill}\index{Microsoft} También sería el lugar a donde \textbf{Bill
Gates}, fundador de \textbf{Microsoft} enviaría una famosa carta justificando la
privatización y comercialización del software mediante el actual modelo de
licencias. Gates alegaba que el software no debía ser compartido (práctica
habitual en esa época) sino que los usuarios debían pagar un permiso (licencia)
para tener derecho a su uso. La carta fue tomada con gran aceptación y permitió
que el desarrollo de software se transformara en una industria millonaria.

\index{Apple II}\index{Commodore 64}\index{BBC Micro}\index{Intellivision}
\index{ColecoVision}\index{Atari 2600}\index{Magnavox Odyssey} En los 80s llega
el boom de las computadoras comerciales y decenas de microcomputadoras aparecen
en el mercado, como la \textbf{Apple II}, la \textbf{Commodore 64}, la
\textbf{BBC Micro}, o \textbf{TRS 80}. También aparecen en la escena las
primeras consolas de videojuegos, como la \textbf{Atari 2600}, la
\textbf{ColecoVision}, la \textbf{Intellivision} o la \textbf{Magnavox Odyssey}.

El público comenzaría a acostumbrarse a estos dispositivos, y a demandar mayor
producción y más características. Las computadoras pasarían a ser un elemento
fundamental en muchas industrias y negocios, así como un valioso recurso en
instituciones educativas.

\subsection{Los primeros sistemas operativos}
\index{Sistema Operativo}
\label{chap:historia_computadoras:subsec:sistemas_operativos}

\wraprimage{unidades/1_computadoras/2_historia_computadoras/imagenes/cpm.jpg}
{CP/M corriendo sobre un monitor de fósforo verde en una Sanco 8001.}
{Fotografía de Mspetch.}

\textbf{La mayoría de las primeras microcomputadoras no permitían al usuario
hacer otra cosa que no fuera de programar}. La mayoría traía incluido un
``manual de usuario'' que enseñaba a los usuarios a programar en el equipo, el
cual, generalmente incluía el lenguaje de programación BASIC. Esto hacía que los
usuarios requirieran aprender una serie de conocimientos para nada sencillos
solo para poder operar la unidad. Eso si, los conocimientos aprendidos permitían
realizar cualquier cosa con el equipo, librado solo a la imaginación del usuario
y a las capacidades técnicas del hardware.

Sin embargo, este modelo traía aparejado la problemática de un bajo número de
usuarios, y una resistencia por parte de empresas e instituciones de adoptar
computadoras debido al alto costo de capacitación del personal. Con la intención
de solventar ese problema surge la idea de los \textbf{sistemas operativos}.

Un \textbf{sistema operativo} consistía en un programa que corría de forma
constante en la computadora, y permitía al usuario escribir instrucciones que
requiriera de la máquina, y esta las llevaría adelante. Así, un usuario podía
solicitarle que realice un cálculo, ejecute un juego, o lo que requiriera del
equipo, sin necesidad de aprender a programar. Esto requería por supuesto que la
computadora incluyera software capaz de llevar adelante muchas tareas genéricas.
Así, aparecen los primeros programas como procesadores de documentos, planillas
de cálculo y bases de datos.\autocite[cap. 3]{ceruzzi_2003}

\index{UNIX}
En las grandes computadoras que existían en las universidades y entidades
gubernamentales, el sistema operativo por defecto era \textbf{UNIX}, creado por
\textbf{Bell Labs (AT\&T)}. El sistema se distribuía de forma libre en un
inicio, pero luego AT\&T decidió comenzar a vender el producto. Esto llevó a que
algunas universidades buscaran reemplazar UNIX con otra cosa.

\index{CP/M}\index{DOS}\index{Kildall, Gary}\index{MS-DOS}\index{PC} En las
microcomputadoras aparecen sistemas como \textbf{CP/M}, creado por \textbf{Gary
Kildall}, y \textbf{DOS} (Disk Operating System), que en realidad no es un
sistema operativo, sino un conjunto de sistemas, pues cada fabricante solía
crear el suyo propio, y comercializarlo junto con su computadora (Y no eran
necesariamente compatibles entre si). Tal vez el más popular sea de estos
últimos sea \textbf{MS-DOS} de \textbf{Microsoft}. \textbf{MS-DOS} supo ganarse
al mercado gracias a que era el sistema por defecto de las computadoras
\textbf{PC} (Personal Computer). PC era una gama de modelos de computadoras
vendidas por \textbf{IMB}, de gran éxito comercial por poseer \textbf{partes
fácilmente intercambiables}, y por licenciar el diseño de componentes a diversas
empresas que creaban clones económicos de muchos componentes.

\index{Macintosh}\index{Apple}\index{Apple
Macintosh}\index{Windows}\index{Microsoft Windows} \textbf{Apple} lanzaría en
1984 la \textbf{Apple Macintosh}, un modelo de computadora que fue el primero en
venir de serie con un sistema operativo que incluía un entorno gráfico y mouse.
Si bien no fue el primer sistema operativo gráfico (ya se habían hecho varios
experimentos en diversos sistemas), al incluirlo de serie, puso la idea en el
aire de que ese era el futuro, y pronto fue copiado por otros. Por su parte, la
primera versión de \textbf{Windows}, el sistema operativo de \textbf{Microsoft}
que hoy sigue siendo comercializado, vería la luz en 1985.

\begin{knowwhat}\index{XEROX PARC} Apple tomó la idea del mouse y de la interfaz
    gráfica de experimentos que se realizaban en el Centro de Investigación de
    Palo Alto de Xerox, conocido como \textbf{Xerox PARC}. Este centro fue la
    cuna de la computadora personal como hoy la conocemos, además de otros
    inventos como el mouse, la interfaz gráfica, la metáfora de escritorio, la
    impresión láser, las redes ethernet, la programación orientada a objetos, la
    computación ubicua, entre otras tantas cosas.\autocite{haltzik_2000}
\end{knowwhat}

\index{Amiga OS}\index{BeOS} Para mediados de los 80 prácticamente no se
comercializaban computadoras que no tuvieran un sistema operativo pre-instalado.
Algunas venían incluso con más de uno, permitiendo al usuario elegir su sistema
de preferencia. Ningún sistema mantenía la hegemonía total, por lo que todavía
había un mercado para el desarrollo de nuevos sistemas operativos. Así surgen
sistemas como \textbf{Amiga OS}, o \textbf{BeOS}, entre otros.

\subsection{El Software Libre}
\index{Software Libre}
\label{chap:historia_computadoras:subsec:software_libre}

Una consecuencia directa de la masificación del uso de computadoras fue la
\textbf{privatización del software}. El software pasa a considerarse una obra
intelectual, de forma similar a un libro, una canción o una película. Es decir,
\textbf{el software pasa a tener derechos de autor (copyright)}.

Ademas, por las características técnicas del software, tales como la posibilidad
de replicar el mismo en tantas máquinas como se quiera, o de utilizarlo con
fines que al autor no considera apropiados, hacen que el software no se comporte
como los libros, música o películas de la época.

Así, \textbf{el software no se vende, se licencia}. Es decir, uno compra la
posibilidad de utilizar el software de una forma determinada (una cantidad
específica de equipos, usarlo con determinados fines, compartirlo de determinada
forma, etc.).

\begin{definition}\index{Licencia de Software} Una \textbf{licencia de software}
    es un contrato entre el licenciante (autor/titular de los derechos de
    explotación/distribución) y el licenciatario (usuario consumidor,
    profesional o empresa) del programa informático, para utilizarlo cumpliendo
    una serie de términos y condiciones establecidas dentro de sus cláusulas.
\end{definition}

\index{Stallman, Richard}\index{Free Software Foundation}\index{Proyecto GNU}
Esta práctica pasa a ser el estándar en el desarrollo de software de la época.
Sin embargo, en 1985, un programador llamado \textbf{Richard Stallman}, cansado
de problemas asociados al copyright del software, inicia un movimiento que
involucra tanto ideas de izquierda como cuestiones técnicas asociadas al
software, el \textbf{movimiento de software libre}. Poco tiempo después fundaría
la \textbf{Free Software Foundation} y el \textbf{proyecto GNU}, con la
intención de promover la creación y el uso del software
libre.\autocite{salus_2008}

\wraprimage{unidades/1_computadoras/2_historia_computadoras/imagenes/richard_stallman.jpg}
{Richard Stallman en una charla en Madrid (2016).} {Fotografía de Rubén Ojéda.}

\index{Copyleft}
Stallman acuña el término \textbf{copyleft}, como una alternativa al
\textbf{copyright}. En este caso, una obra intelectual sigue teniendo derechos
de autor, pero el autor manifiesta al momento de su creación de forma explicita
su voluntad de permitir a otros utilizar su obra para lo que sea, siempre y
cuando esta se mantenga libre (es decir, que los derivados de dicha obra
compartan la misma característica de poder ser utilizados como se desee).

Esto supone un cambio radical en la industria del software. Involucra el
compartir el \textbf{código fuente} de los programas, y permitir que cualquiera
trabaje sobre el. Stallman sostiene que esto permite que la sociedad en su
conjunto se beneficie de las mejoras que se vayan realizando.

\index{Open Source Initiative}
Las empresas en principio juzgaron fuertemente al movimiento, pero las bondades
del mismo pronto se hicieron evidentes. Al tener cientos de programadores que
participan de forma voluntaria en un producto, el mismo termina por contar con
mayor calidad y siendo más seguro. Así, aparece la \textbf{Open Source
Initiative}, una iniciativa que comparte las prácticas del movimiento del
software libre, pero, cuyos fines no son los mismos; mientras el primero
persigue fines altruísticos, el segundo solo busca una mejora en la rentabilidad
y beneficios comerciales.

Se dice en general que el software es \textbf{libre} si sus creadores adhieren a
las políticas propuestas por la \textbf{Free Software Foundation}, y que es
\textbf{open source} si simplemente abren su código pero no comparten la
filosofía. El resto del software se denomina \textbf{privativo}. En muchas
ocaciones no se realiza la distinción entre los términos libre y open source,
considerando a todo el software de código abierto como libre.

Hay que tener en cuenta que el software libre es general, pero no
necesariamente, gratuito. Esto es uno de los principales incentivos para los
usuarios, pero a esto se le debe adicional la confiabilidad en el software, pues
su código ha sido visto por muchos desarrolladores que no tienen interés
comercial en el mismo de forma directa, y que denunciarían cualquier acción que
pudiera perjudicar al usuario final.

Hoy en día, la mayoría de los programas comerciales cuentan con una alternativa
``libre''. En muchas ocaciones, la alternativa libre es superior a la
``privativa'', pero en otras ocaciones, la falta de financiamiento y prácticas
monopólicas hacen que las alternativas libres no estén a la altura de sus
contrapartes comerciales.

Este movimiento se ha vuelto tan grande que incluso empresas como Microsoft o
IBM ahora desarrollan y apoyan el software libre u open source. Muchas empresas
se dedican incluso a la venta de servicios de soporte o desarrollo de soluciones
de software libre, por lo que el software libre no representa una amenaza a la
industria del desarrollo de software.

\subsection{Las redes, Internet, y la globalización}
\index{Redes}\index{Internet}
\label{chap:historia_computadoras:subsec:internet}

\index{SAGE}
No tardó mucho tiempo en que los usuarios quisieran compartir información entre
computadoras ubicadas en distintos lugares físicos. Ya en 1950, el el sistema de
radares militares de Estados Unidos, conocido como \textbf{SAGE}, se puso en
línea, conectando computadoras de diversos puntos del país. Por su parte, en la
Unión Soviética en 1959 se propone un plan de defensa que incluye una red de
computadoras ubicadas en lugares estratégicos.

\index{ARPANET}
Sin embargo, el verdadero hito en materia de redes se produciría en 1969, con la
creación de \textbf{ARPANET} (Advance Research Projects Agency Network). Nacida
como un proyecto del Departamento de Defensa de los Estados Unidos, ARPANET
sería la primer red en utilizar un protocolo estandarizado para comunicar
diversas computadoras. Empezó uniendo los equipos de diversas universidades en
la costa oeste, para expandirse velozmente hacia la costa este y centro del
país.

\image{unidades/1_computadoras/2_historia_computadoras/imagenes/internet_submarine.png}
{Mapa de las conexiones submarinas de Internet.} {Datos de Greg Mahlknecht sobre
mapa de OpenStreetMap.}

\index{NORSAR}
En Europa, diversas organizaciones generaban sus propias redes, algunas de las
cuales colaboraban con la ARPANET adoptando sus protocolos, como \textbf{NORSAR}
en Noruega, o redes en las universidades de Inglaterra. ARPANET evolucionaría
rápidamente para convertirse en lo que hoy llamamos
\textbf{Internet}.\autocite{hafner_1998}

\begin{knowwhat}
Internet se basa en una red de computadoras conectadas por cables. Hay cables
submarinos que conectan todos los lugares del mundo, así como cables enterrados
bajo la tierra en diversos países que no limitan con algún océano.

Muchas personas creen que Internet funciona mediante conexiones satelitales. Si
bien es cierto que existen conexiones de estas características, las velocidades
de conexión y los altos costos de mantener ese servicio, lo vuelven inviables
para un servicio tan masivo.
\end{knowwhat}

\section{La actualidad y el futuro}
\label{chap:historia_computadoras:sec:actualidad}

Avanzamos mucho desde esas primeras microcomputadoras. Hoy, es normal que en los
países desarrollados y emergentes la mayoría de la población cuente con una
computadora. Además, la penetración de internet en la población de dichos
lugares suele ser elevada o encontrarse en constante aumento, tal es el caso de
Argentina.

\begin{knowwhat}
En algunos países el acceso a internet es considerado un derecho constitucional.
En esos lugares entienden que el acceso a la información debe ser irrestricto, y
por tanto, el estado debe garantizar alguna forma de que las personas accedan a
Internet.
\end{knowwhat}

Los dispositivos se han reducido en tamaño y aumentado en potencia, pero siguen
basados en los mismos principios que las microcomputadoras de los 70. Un celular
moderno es incluso cientos de veces más potente que esas primigenias
computadoras que, no obstante, llevaron al hombre a la luna.

Nuevas tecnologías como el GPS, las redes inalámbricas, las conexiones de datos
móviles, entre otras, nos posicionan en mundo donde la tecnología es ubicua.
Además, nuevos avances, aún en desarrollo, pero ya una realidad, nos plantean
oportunidades, a la vez que desafíos de cara a un futuro donde la tecnología
estará cada vez más integrada en nuestro día a día.

La concepción de la información como un elemento fundamental del universo,
inherente a la física o a la biología, plantea nuevos modelos computacionales
que presentan inicialmente cambios radicales en la forma en la que pensamos en
computación, así como también auguran avances en áreas como la física, la
astronomía o la medicina.

\subsection{La internet de las cosas y Big Data}
\index{Internet de las Cosas}\index{IoT}
\label{chap:historia_computadoras:subsec:iot}

Uno de los escenarios en donde hay cada vez más desarrollo y más trabajos en
ciencias de la computación tiene que ver con el concepto de \textbf{``Internet
de las cosas'' (IoT)}. Es un concepto que se refiere a una interconexión digital
de objetos cotidianos con internet.\autocite{iot_2008}

Esto implica que virtualmente todo objeto tenga algún tipo de identificador de
radiofrecuencia que le permita al dispositivo conectarse a Internet. Con objeto
nos referimos a autos, heladeras, tostadoras, lámparas, libros, paquetes,
envoltorios, etc. Virtualmente todo. Kevin Ashtor, quien acuñó el término
expresa los siguiente:

\image{unidades/1_computadoras/2_historia_computadoras/imagenes/linkedin_luc_legay.jpg}
{Visualización de las conexiones del usuario Luc Legay en la plataforma
LinkedIn.} {Imágen de Luc Legay.}

``Las computadoras actuales —y, por tanto, internet— son prácticamente
dependientes de los seres humanos para recabar información. Una mayoría de los
casi 50 petabytes de datos disponibles en internet fueron inicialmente creados
por humanos, a base de teclear, presionar un botón, tomar una imagen digital o
leer un código de barras. Los diagramas convencionales de internet, dejan fuera
a los routers más importantes de todos: las personas. El problema es que las
personas tienen un tiempo, una atención y una precisión limitados, y no se les
da muy bien conseguir información sobre cosas en el mundo real. Y eso es un gran
obstáculo. Somos cuerpos físicos, al igual que el medio que nos rodea. No
podemos comer bits, ni quemarlos para resguardarnos del frío, ni meterlos en
tanques de gas. Las ideas y la información son importantes, pero las cosas
cotidianas tienen mucho más valor. Aunque, la tecnología de la información
actual es tan dependiente de los datos escritos por personas que nuestras
computadoras saben más sobre ideas que sobre cosas. Si tuviéramos computadoras
que supieran todo lo que tuvieran que saber sobre las 'cosas', mediante el uso
de datos que ellas mismas pudieran recoger sin nuestra ayuda, nosotros podríamos
monitorizar, contar y localizar todo a nuestro alrededor, de esta manera se
reducirían increíblemente gastos, pérdidas y costes. Sabríamos cuándo
reemplazar, reparar o recuperar lo que fuera, así como conocer si su
funcionamiento estuviera siendo correcto. El internet de las cosas tiene el
potencial para cambiar el mundo tal y como hizo la revolución digital hace unas
décadas. Tal vez incluso hasta más.''
\textcite{ashton_2009}

La internet de las cosas no es un escenario futurista lejano, pues distintas
estimaciones proyectan que para 2020 ya habrá aproximadamente unos 20 mil
millones de dispositivos conectados, siendo la cifra actual de unos 9 mil
millones.
\autocite{gartner_2017}

\index{Domotica@Domótica}
Este tipo de interacciones con dispositivos tendría implicancias prácticas en
áreas como la \textbf{domótica} (automatización de hogares), el
\textbf{marketing}, y la \textbf{logística}. Sin embargo, a medida que la
tendencia crece surgen diversas preocupaciones y problemáticas. Por un lado,
aspectos relacionados a la seguridad de estos dispositivos, pues se ha
comprobado que muchos de ellos pueden ser vulnerados con facilidad, algo que
sucedió incluso con una cámara de monitoreo para bebés, pudiendo el atacante
tener acceso a la filmación. Por otro lado, la cantidad de datos a manejar
representa un volumen significativo, lo que trae aparejados desafíos tanto a
nivel de ingeniería (servidores, energía, etc.) como a nivel de desarrollo de
software (manejando grandes volúmenes de datos).

\index{Big Data}
Así, esta área va de la mano con el desarrollo de \textbf{Big Data}, un concepto
que hace referencia a conjuntos de datos tan grandes y complejos que requieren
de  aplicaciones informáticas no tradicionales de procesamiento de datos para
tratarlos adecuadamente. El análisis de los datos permite elaborar complejas
estadísticas o predicciones.\autocite[vid.]{warden_2011}

Pero el Big Data no solo se produce a partir del internet de las cosas, sino que
otros datos, por ejemplo, aquellos generados por seres humanos al utilizar
tecnología también son sujetos de esta disciplina. Hoy en día empresas como
Google o Facebook recolectan y venden una gigantesca cantidad de datos de sus
usuarios, que involucran sus gustos, sus conocidos, su ubicación en distintos
momentos, entre otras muchas cosas, y que se utilizan para determinar la
publicidad más adecuada para cada segmento, así como para hacer predicciones
sobre su comportamiento y consumo. No solo es publicidad, sino que también son
utilizados esos datos para manipular las elecciones en diferentes
países.\autocite{perfil_2018_03_20}

\subsection{La inteligencia artificial y la automatización}
\index{Inteligencia Artificial}\index{Automatizacion@Automatización}
\label{chap:historia_computadoras:subsec:ia}

Otra de las áreas en donde hay un especial interés dado su amplio potencial es
en la \textbf{inteligencia artificial}. Coloquialmente, el término se aplica
cuando una máquina imita las funciones ``cognitivas'' que los humanos asocian
con otras mentes humanas, como por ejemplo: ``aprender'' y ``resolver
problemas''. Técnicamente puede definirse como la capacidad de un sistema para
interpretar correctamente datos externos, para aprender de dichos datos y
emplear esos conocimientos para lograr tareas y metas concretas a través de la
adaptación flexible.\autocite{kaplan_2019}

La inteligencia artificial permite \textbf{automatizar} procesos previamente
realizados por humanos. Dentro de las aplicaciones prácticas ya destacan
actualmente la participación de robots automatizados en procesos industriales, o
de inteligencias artificiales en el mercado de valores, con resultados que
superan ampliamente a los que podrían obtener cualquier grupo de seres humanos.
También se utilizan sistemas de inteligencia artificial en procesos de filtrado
de spam en correos electrónicos, o generación de listas musicales, así como en
videojuegos. Hoy en día incluso hay empresas que ofrecen para empresas de
noticias, servicios de inteligencia artificial con autómatas capaces de redactar
notas, por ejemplo, de eventos deportivos, basándose solamente en las
estadísticas del juego. También existen sistemas que permiten eliminar puestos
de gerencia media, al identificar el trabajo realizado por estos y reemplazarlos
por sistemas automáticos. Ya existen también, autos capaces de manejarse solos,
y de tomar la mejor decisión de conducción ante situaciones
imprevistas.\index{Cuarta Revolucion Industrial@Cuarta Revolución Industrial} Se
espera cada vez más y más intervención de este tipo de tecnologías, en
transporte, en medicina, en telecomunicaciones, en política, etc. Su
incorporación será tan grande que se habla de una ``\textbf{cuarta revolución
industrial}'', la cual cambiará significativamente el panorama económico y
laboral del planeta, al punto de que se estima que el un alto porcentaje de la
población quedará sin empleo, aunque también se pronostica la aparición de
nuevos puestos de trabajo asociados a estas tecnologías.\autocite{wef_2016}


\subsection{La computación cuántica y la computación biológica}
\label{chap:historia_computadoras:subsec:cuantica}

La última área de interés que mencionaremos está relacionado a nuevos modelos
computacionales que vienen a romper el paradigma de computadora actual. En ese
sentido hay dos grandes modelos que llenan de emoción a los científicos.

\wraprimage{unidades/1_computadoras/2_historia_computadoras/imagenes/ibm_quantum.jpg}
{Parte de la computadora cuántica Q de IBM.} {Fotografía de Lars Plougmann.}

\index{Computacion Cuantica@Computación Cuántica}
El primero, la \textbf{computación cuántica}, sería capaz de resolver de forma
eficiente algunos problemas que no pueden resolverse con computadoras clásicas,
permitiendo la implementación de nuevos algoritmos. Los avances tanto en la
parte formal de esta ciencia, así como en la ingeniería de la misma, auguran un
gran futuro para este tipo de computadoras. Las mismas utilizan principios de la
física cuántica, tales como la superposición o el entrelazamiento cuántico para
manipular información, la cual está codificada como alguna propiedad cuántica de
una partícula (por ejemplo la polarización de un fotón, o el spin de un
electrón).\autocite{nielsen_2011}

Las primigenias computadoras cuánticas ya están entre nosotros. Compañías como
IBM, Microsoft y Google ya tienen desarrollos sobre está tecnología. Sin
embargo, todavía son propensas a errores, y lo que ofrecen puede realizarse
mediante simulaciones en computadoras clásicas, por lo que todavía no ofrecen
mejoras sustanciales. Sin embargo, la tecnología avanza rápidamente y se espera
que en pocos años pasen a ser una realidad.\autocite{mit_tech_2018_02}

\index{Computacion Biologica@Computación Biológica}
El segundo modelo es el de las \textbf{computadoras biológicas}. Este tipo de
computadoras se hacen posibles gracias a la nanobiotecnología, y permitirían
manipular proteínas y ADN para realizar cálculos computacionales. Este tipo de
computadoras permitiría manipular elementos biológicos, generando complejas
interacciones, lo cual podría resultar en nuevos medicamentos o tratamientos
para enfermedades.\autocite{freitas_1999} No solo eso, sino que la capacidad de
los sistemas biológicos de autoreplicarse permitiría crear computadoras con un
costo sumamente bajo, lo cual sería una ventaja económica sustancial frente a
sistemas que requieren procesos manuales para su fabricación.

Estos nuevos modelos computacionales surgen de la combinación de las ciencias de
la computación con otras disciplinas (física y biología respectivamente). Este
enfoque nos demuestra que las ciencias de la computación están todavía en una
etapa embrionaria, pues la interpretación de cualquier elemento como
``información'' da como resultado estas tecnologías que nos obligan a repensar
seriamente las posibilidades y los límites de la computación. Por esto muchos
científicos se emocionan con las posibilidades que auguran estas nuevas
tecnologías, aunque muchas de ellas sean todavía teóricas.

\section{Actividades}
\index{Actividades}
\label{chap:historia_computadoras:subsec:actividades}

Esta sección presenta una serie de ejercicios y preguntas para que realice. En
este caso, se pide investigue en Internet para poder contestar las preguntas a
continuación:

\begin{exercise}
¿Cuál fue la primer computadora en argentina? ¿Para que se usaba? ¿Quién la
trajo al país?
\end{exercise}

\begin{exercise}
¿Qué es la ley de Moore? ¿Se cumple actualmente?
\end{exercise}

\begin{exercise}
¿De quién son los cables submarinos de Internet?
\end{exercise}

\begin{exercise}
Sabía que en Argentina se desarrollaron varias distribuciones de Linux. Averigüe
el nombre y la historia de algunas de ellas.
\end{exercise}

\begin{exercise}
¿Conoce alguna de las microcomputadoras emblemática? ¿Cuál? Si no conoce
ninguna, investigue que computadoras marcaron esa época.
\end{exercise}

\begin{exercise}
¿Qué lenguajes de programación conoce? ¿Sabe cuales son los más populares?
\end{exercise}










